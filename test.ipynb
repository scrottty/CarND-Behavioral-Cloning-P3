{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[:5]:  [ 'C:\\\\Users\\\\steineo\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\data_udacity\\\\IMG\\\\center_2017_04_16_23_01_22_517.jpg'\n",
      " 'C:\\\\Users\\\\steineo\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\data_udacity\\\\IMG\\\\center_2017_04_16_22_59_46_256.jpg'\n",
      " 'C:\\\\Users\\\\steineo\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\data_udacity\\\\IMG\\\\center_2017_04_16_23_04_30_388.jpg'\n",
      " 'C:\\\\Users\\\\steineo\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\data_udacity\\\\IMG/center_2016_12_01_13_35_33_556.jpg'\n",
      " 'C:\\\\Users\\\\steineo\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\data_udacity\\\\IMG\\\\center_2017_04_16_23_05_26_090.jpg']\n",
      "Y_train[:5]:  [ 0.00982136  0.06079779  0.00982136  0.          0.14579619]\n",
      "X_train data type : object\n",
      "Y_train data type : float32\n",
      "X_val data type : float64\n",
      "Y_val data type : float64\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 16, 16, 32)    6176        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16, 16, 32)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 4, 4, 64)      131136      activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu2 (Activation)               (None, 4, 4, 64)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 2, 2, 128)     131200      relu2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 2, 2, 128)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 2, 2, 128)     65664       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 2, 2, 128)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 512)           0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           65664       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 128)           0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           16512       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             129         dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 416,481\n",
      "Trainable params: 416,481\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Miniconda3\\envs\\carnd-term1\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Program Files\\Miniconda3\\envs\\carnd-term1\\lib\\threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Program Files\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-1-2aecb309a697>\", line 175, in generate_train_batch\n",
      "    x,y = generate_training_example(X_train,X_left,X_right,Y_train)\n",
      "  File \"<ipython-input-1-2aecb309a697>\", line 138, in generate_training_example\n",
      "    image,steering = read_next_image(m,lcr,X_train,X_left,X_right,Y_train)\n",
      "  File \"<ipython-input-1-2aecb309a697>\", line 65, in read_next_image\n",
      "    image = plt.imread(X_left[m].strip(' '))\n",
      "  File \"C:\\Program Files\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\matplotlib\\pyplot.py\", line 2315, in imread\n",
      "    return _imread(*args, **kwargs)\n",
      "  File \"C:\\Program Files\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\matplotlib\\image.py\", line 1227, in imread\n",
      "    im = pilread(fname)\n",
      "  File \"C:\\Program Files\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\matplotlib\\image.py\", line 1205, in pilread\n",
      "    with Image.open(fname) as image:\n",
      "  File \"C:\\Program Files\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\PIL\\Image.py\", line 2312, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\steineo\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\data_udacity\\\\ IMG/left_2016_12_01_13_45_48_476.jpg'\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2aecb309a697>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    229\u001b[0m history = model.fit_generator(train_generator,\n\u001b[0;32m    230\u001b[0m                     \u001b[0msamples_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                     validation_data=(X_val,Y_val),verbose=1)\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[0mjson_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[1;32mC:\\Program Files\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1526\u001b[0m                                          \u001b[1;34m'(x, y, sample_weight) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1527\u001b[0m                                          \u001b[1;34m'or (x, y). Found: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1528\u001b[1;33m                                          str(generator_output))\n\u001b[0m\u001b[0;32m   1529\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m                         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout,Convolution2D,MaxPooling2D,Flatten,Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "data_dir = './data_udacity/'\n",
    "data_csv = './data_udacity/driving_log.csv'\n",
    "model_json = 'model.json'\n",
    "model_weights = 'model.h5'\n",
    "\n",
    "#col_names = ['center', 'left','right','steering','throttle','brake','speed']\n",
    "training_dat = pd.read_csv(data_csv,names=None)\n",
    "training_dat.head()\n",
    "\n",
    "\n",
    "training_dat[['left','center','right']]\n",
    "X_train = training_dat[['left','center','right']]\n",
    "Y_train = training_dat['steering']\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# get rid of the pandas index after shuffling\n",
    "X_left  = X_train['left'].as_matrix()\n",
    "X_right = X_train['right'].as_matrix()\n",
    "X_train = X_train['center'].as_matrix()\n",
    "X_val   = X_val['center'].as_matrix()\n",
    "Y_val   = Y_val.as_matrix()\n",
    "Y_train = Y_train.as_matrix()\n",
    "\n",
    "Y_train = Y_train.astype(np.float32)\n",
    "Y_val   = Y_val.astype(np.float32)\n",
    "\n",
    "\n",
    "if data_dir=='./data/udacity':\n",
    "    X_train = X_train.apply(lambda x: data_dir+'/'+x)\n",
    "    X_left = X_left.apply(lambda x: data_dir+'/'+x)\n",
    "    X_right = X_right.apply(lambda x: data_dir+'/'+x)\n",
    "\n",
    "# print('X_train[:5]: ',X_train[:5])\n",
    "# print('Y_train[:5]: ',Y_train[:5])\n",
    "\n",
    "\n",
    "def read_next_image(m,lcr,X_train,X_left,X_right,Y_train):\n",
    "    # assume the side cameras are about 1.2 meters off the center and the offset to the left or right \n",
    "    # should be be corrected over the next dist meters, calculate the change in steering control\n",
    "    # using tan(alpha)=alpha\n",
    "\n",
    "    offset=1.0 \n",
    "    dist=20.0\n",
    "    steering = Y_train[m]\n",
    "    if lcr == 0:\n",
    "        image = plt.imread(X_left[m].strip(' '))\n",
    "        dsteering = offset/dist * 360/( 2*np.pi) / 25.0\n",
    "        steering += dsteering\n",
    "    elif lcr == 1:\n",
    "        image = plt.imread(X_train[m].strip(' '))\n",
    "    elif lcr == 2:\n",
    "        image = plt.imread(X_right[m].strip(' '))\n",
    "        dsteering = -offset/dist * 360/( 2*np.pi)  / 25.0\n",
    "        steering += dsteering\n",
    "    else:\n",
    "        print ('Invalid lcr value :',lcr )\n",
    "    \n",
    "    return image,steering\n",
    "\n",
    "def random_crop(image,steering=0.0,tx_lower=-20,tx_upper=20,ty_lower=-2,ty_upper=2,rand=True):\n",
    "    # we will randomly crop subsections of the image and use them as our data set.\n",
    "    # also the input to the network will need to be cropped, but of course not randomly and centered.\n",
    "    shape = image.shape\n",
    "    col_start,col_end =abs(tx_lower),shape[1]-tx_upper\n",
    "    horizon=60;\n",
    "    bonnet=136\n",
    "    if rand:\n",
    "        tx= np.random.randint(tx_lower,tx_upper+1)\n",
    "        ty= np.random.randint(ty_lower,ty_upper+1)\n",
    "    else:\n",
    "        tx,ty=0,0\n",
    "    \n",
    "    #    print('tx = ',tx,'ty = ',ty)\n",
    "    random_crop = image[horizon+ty:bonnet+ty,col_start+tx:col_end+tx,:]\n",
    "    image = cv2.resize(random_crop,(64,64),cv2.INTER_AREA)\n",
    "    # the steering variable needs to be updated to counteract the shift \n",
    "    if tx_lower != tx_upper:\n",
    "        dsteering = -tx/(tx_upper-tx_lower)/3.0\n",
    "    else:\n",
    "        dsteering = 0\n",
    "    steering += dsteering\n",
    "    \n",
    "    return image,steering\n",
    "\n",
    "def random_shear(image,steering,shear_range):\n",
    "    rows,cols,ch = image.shape\n",
    "    dx = np.random.randint(-shear_range,shear_range+1)\n",
    "    #    print('dx',dx)\n",
    "    random_point = [cols/2+dx,rows/2]\n",
    "    pts1 = np.float32([[0,rows],[cols,rows],[cols/2,rows/2]])\n",
    "    pts2 = np.float32([[0,rows],[cols,rows],random_point])\n",
    "    dsteering = dx/(rows/2) * 360/(2*np.pi*25.0) / 6.0    \n",
    "    M = cv2.getAffineTransform(pts1,pts2)\n",
    "    image = cv2.warpAffine(image,M,(cols,rows),borderMode=1)\n",
    "    steering +=dsteering\n",
    "    \n",
    "    return image,steering\n",
    "\n",
    "def random_brightness(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = 0.8 + 0.4*(2*np.random.uniform()-1.0)    \n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "def random_flip(image,steering):\n",
    "    coin=np.random.randint(0,2)\n",
    "    if coin==0:\n",
    "        image,steering=cv2.flip(image,1),-steering\n",
    "    return image,steering\n",
    "        \n",
    "\n",
    "def generate_training_example(X_train,X_left,X_right,Y_train):\n",
    "    m = np.random.randint(0,len(Y_train))\n",
    "#    print('training example m :',m)\n",
    "#     lcr = np.random.randint(0,3)\n",
    "    lcr = 1\n",
    "    #lcr = 1\n",
    "#    print('left_center_right  :',lcr)\n",
    "    image,steering = read_next_image(m,lcr,X_train,X_left,X_right,Y_train)\n",
    "#    print('steering :',steering)\n",
    "#    plt.imshow(image)\n",
    "#     image,steering = random_shear(image,steering,shear_range=100)\n",
    "#    print('steering :',steering)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(image)    \n",
    "#     image,steering = random_crop(image,steering,tx_lower=-20,tx_upper=20,ty_lower=-10,ty_upper=10)\n",
    "#    print('steering :',steering)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(image)\n",
    "#     image,steering = random_flip(image,steering)\n",
    "#    print('steering :',steering)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(image)\n",
    "    \n",
    "#     image = random_brightness(image)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(image)\n",
    "    \n",
    "    return image,steering\n",
    "\n",
    "def get_validation_set(X_val,Y_val):\n",
    "    X = np.zeros((len(X_val),64,64,3))\n",
    "    Y = np.zeros(len(X_val))\n",
    "    for i in range(len(X_val)):\n",
    "        x,y = read_next_image(i,1,X_val,X_val,X_val,Y_val)\n",
    "        X[i],Y[i] = random_crop(x,y,tx_lower=0,tx_upper=0,ty_lower=0,ty_upper=0)\n",
    "    return X,Y\n",
    "    \n",
    "\n",
    "def generate_train_batch(X_train,X_left,X_right,Y_train,batch_size = 32):\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, 64, 64, 3))\n",
    "    batch_steering = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            x,y = generate_training_example(X_train,X_left,X_right,Y_train)\n",
    "            batch_images[i_batch] = x\n",
    "            batch_steering[i_batch] = y\n",
    "        yield batch_images, batch_steering\n",
    "\n",
    "\n",
    "\n",
    "batch_size=200\n",
    "train_generator = generate_train_batch(X_train,X_left,X_right,Y_train,batch_size)\n",
    "X_val,Y_val = get_validation_set(X_val,Y_val)\n",
    "\n",
    "print('X_train data type :',X_train.dtype)\n",
    "print('Y_train data type :',Y_train.dtype)\n",
    "print('X_val data type :',X_val.dtype)\n",
    "print('Y_val data type :',Y_val.dtype)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.0,input_shape=(64,64,3)))\n",
    "model.add(Convolution2D(32, 8,8 ,border_mode='same', subsample=(4,4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 8,8 ,border_mode='same',subsample=(4,4)))\n",
    "model.add(Activation('relu',name='relu2'))\n",
    "model.add(Convolution2D(128, 4,4,border_mode='same',subsample=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, 2,2,border_mode='same',subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(1))\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "restart=True\n",
    "if os.path.isfile(model_json) and restart:\n",
    "    try:\n",
    "        with open(model_json) as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "            model.load_weights(model_weights)    \n",
    "        print('loading trained model ...')\n",
    "    except Exception as e:\n",
    "        print('Unable to load model', model_name, ':', e)\n",
    "        raise    \n",
    "\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "\n",
    "nb_epoch=10\n",
    "history = model.fit_generator(train_generator,\n",
    "                    samples_per_epoch=20000, nb_epoch=nb_epoch,\n",
    "                    validation_data=(X_val,Y_val),verbose=1)\n",
    "\n",
    "json_string = model.to_json()\n",
    "\n",
    "print('Save the model')\n",
    "\n",
    "try:\n",
    "    os.remove(model_json)\n",
    "    os.remove(model_weights)\n",
    "except OSError:\n",
    "    pass   \n",
    "\n",
    "with open(model_json, 'w') as outfile:\n",
    "    json.dump(json_string, outfile)\n",
    "model.save_weights(model_weights)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
